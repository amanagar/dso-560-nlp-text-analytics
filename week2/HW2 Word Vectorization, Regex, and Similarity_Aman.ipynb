{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 (Due 6:29pm PST March 29th, 2022): Word Vectorization, Regex Practice, and Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may work with **one other person on this assignment**. You may also work independently if you prefer.\n",
    "\n",
    "If you just want to be assigned someone to work with, message me on Slack and I will assign you a partner to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Using the **Amazon Toy Reviews Dataset (both positive and negative)**, **process the reviews**.\n",
    "This means you should think briefly about:\n",
    "* what stopwords to remove (should you add any custom stopwords to the set? Remove any stopwords?)\n",
    "* what regex cleaning you may need to perform (for example, are there different ways of saying `broken` that you need to account for?)\n",
    "* stemming/lemmatization (explain in your notebook why you used stemming versus lemmatization). \n",
    "\n",
    "Next, **count-vectorize the dataset**. Use the **`sklearn.feature_extraction.text.CountVectorizer`** examples from `Linear Algebra, Distance and Similarity (Completed).ipynb` and `Text Preprocessing Techniques (Completed).ipynb`.\n",
    "\n",
    "I do not want redundant features - for instance, I do not want `Christmas` and `Christ-mas` to be two distinct columns in your document-term matrix. Therefore, I'll be taking a look to make sure you've properly performed your cleaning, stopword removal, etc. to reduce the number of dimensions in your dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. **Stopwords, Stemming, Lemmatization Practice**\n",
    "\n",
    "Using the **McDonalds Negative Reviews** file from Week 1:\n",
    "* Count-vectorize the corpus. Treat each sentence as a document.\n",
    "\n",
    "How many features (dimensions) do you get when you:\n",
    "* Perform **stemming** and then count-vectorization\n",
    "* Perform **lemmatization** and then **count-vectorization**.\n",
    "* Perform **lemmatization**, remove **stopwords**, and then perform **count-vectorization**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "data1=\" \"\n",
    "data2=\" \"\n",
    "\n",
    "with open(\"../datasets/poor_amazon_toy_reviews.txt\",\"r\") as fp:\n",
    "    data1=fp.read()\n",
    "with open(\"../datasets/good_amazon_toy_reviews.txt\",\"r\") as fp:\n",
    "    data2=fp.read()\n",
    "    \n",
    "data1=data1+\"\\n\"\n",
    "data1=data1+data2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "poor_amazon_toy_reviews = pd.DataFrame( open(\"../datasets/poor_amazon_toy_reviews.txt\", \"r\"), columns=[\"Review\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do not buy these! They break very fast I spun ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Showed up not how it's shown . Was someone's o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You need expansion packs 3-5 if you want acces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"This was to be a gift for my husband for our ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Received a pineapple rather than the advertise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12695</th>\n",
       "      <td>It's a piece of junk...doesn't charge multiple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12696</th>\n",
       "      <td>Really small\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12697</th>\n",
       "      <td>It is contained in glass which is dangerous if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12698</th>\n",
       "      <td>\"Fake. Not original. Every time my 5 yr old ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12699</th>\n",
       "      <td>Poor quality\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12700 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review\n",
       "0      Do not buy these! They break very fast I spun ...\n",
       "1      Showed up not how it's shown . Was someone's o...\n",
       "2      You need expansion packs 3-5 if you want acces...\n",
       "3      \"This was to be a gift for my husband for our ...\n",
       "4      Received a pineapple rather than the advertise...\n",
       "...                                                  ...\n",
       "12695  It's a piece of junk...doesn't charge multiple...\n",
       "12696                                     Really small\\n\n",
       "12697  It is contained in glass which is dangerous if...\n",
       "12698  \"Fake. Not original. Every time my 5 yr old ki...\n",
       "12699                                     Poor quality\\n\n",
       "\n",
       "[12700 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poor_amazon_toy_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_amazon_toy_reviews = pd.DataFrame( open(\"../datasets/good_amazon_toy_reviews.txt\", \"r\"), columns=[\"Review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Excellent!!!\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Great quality wooden track (better than some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my daughter loved it and i liked the price and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Great item. Pictures pop thru and add detail a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was pleased with the product.\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0                                     Excellent!!!\\n\n",
       "1  \"Great quality wooden track (better than some ...\n",
       "2  my daughter loved it and i liked the price and...\n",
       "3  Great item. Pictures pop thru and add detail a...\n",
       "4                  I was pleased with the product.\\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_amazon_toy_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMBINE GOOD AND POOR REVIEWS\n",
    "AllReviews = pd.concat([poor_amazon_toy_reviews,good_amazon_toy_reviews])\n",
    "AllReviews[\"Review\"] = AllReviews[\"Review\"].str.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do not buy these! They break very fast I spun ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Showed up not how it's shown . Was someone's o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You need expansion packs 3-5 if you want acces...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"This was to be a gift for my husband for our ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Received a pineapple rather than the advertise...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review\n",
       "0  Do not buy these! They break very fast I spun ...\n",
       "1  Showed up not how it's shown . Was someone's o...\n",
       "2  You need expansion packs 3-5 if you want acces...\n",
       "3  \"This was to be a gift for my husband for our ...\n",
       "4  Received a pineapple rather than the advertise..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AllReviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords=set(stopwords.words('english'))\n",
    "\n",
    "#COUNTING WORDS TO SEE PATTERNS\n",
    "from collections import Counter\n",
    "def count_words(lines, delimiter=\" \"):\n",
    "    \n",
    "    words = Counter() # instantiate a Counter object called words\n",
    "    for line in lines:\n",
    "        for word in line.split(delimiter):\n",
    "            if word.lower() not in nltk_stopwords:\n",
    "                words[word] += 1 # increment count for word\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cntr=count_words(AllReviews[\"Review\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cntr.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.\n",
    "\n",
    "### i)\n",
    "I would have remove 'didn't' , 'couldn't' , 'doesn't'  stopwords from the NLTK set of stopwords but with full context of use cases as i believe this will be very helpful in certain use case where the whole meaning of teh sentence could change with these words.\n",
    "\n",
    "As from addition point of view I think we could potentially add these to the list as these are high frequency and might not add much value to in analysis in this domain.'would','really','/><br','overall','anyway','anyways'\n",
    "\n",
    " More additions would more likely to be decided relecant to the business use case.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "\n",
    "cleaned_reviews=[]\n",
    "nltk_stopwords=set(stopwords.words('english'))\n",
    "add_stopwords=['would','really','overall','anyway','anyways']\n",
    "for word in add_stopwords:\n",
    "    nltk_stopwords.add(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stopwords\n",
    "for review in AllReviews[\"Review\"]:\n",
    "    words = nltk.word_tokenize(review)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.lower() in nltk_stopwords:\n",
    "            continue\n",
    "        new_words.append(word.lower())\n",
    "    cleaned_review = \" \".join(new_words)\n",
    "    cleaned_reviews.append(cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews_s=pd.Series(cleaned_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"buy ! break fast spun 15 minutes end flew n't waste money . made cheap plastic cracks . buy poi balls work lot better limited funds .\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_reviews_s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.\n",
    "\n",
    "### ii) REGEX CLEANING\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGEX1\n",
    "cleaned_reviews_s=cleaned_reviews_s.str.replace(r'\\b(exact)\\b|\\b(match)\\b|\\b(fit)\\b|\\b(pleased)\\b|\\b(perfect)\\b',\\\n",
    "                              '_perfect_',regex=True, case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGEX2\n",
    "cleaned_reviews_s=cleaned_reviews_s.str.replace(r'\\b(hit)\\b|\\b(good)\\b|\\b(great)\\b|\\b(nice)\\b|\\b(fantastic)\\b|\\b(best)|\\b(excellent)|\\b(high(ly)? recommend(ed)?)\\b|\\b(awesome)\\b',\\\n",
    "                              '_great_',regex=True, case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGEX3\n",
    "cleaned_reviews_s=cleaned_reviews_s.str.replace(r'\\b(purchase(d)?)\\b|\\b(order(s|ed)?)\\b|\\b(bought)\\b',\\\n",
    "                              '_bought_',regex=True, case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGEX4\n",
    "cleaned_reviews_s=cleaned_reviews_s.str.replace(r'\\b(poor(ly|er|est)?)\\b|\\b(terrible)\\b|\\b(wors(e|t)?)\\b|\\b(bad)\\b',\\\n",
    "                              '_bad_',regex=True, case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGEX5\n",
    "cleaned_reviews_s=cleaned_reviews_s.str.replace(r'\\b(dissapointing)\\b|\\b(too small)\\b|\\b(misrepresentation)\\b|\\b(waste(ful)?)\\b|\\b(broke(n)?)\\b|\\b(fake(er|st)?)\\b|\\b(fail(ed)?)\\b|\\b(filmsy)\\b|\\b(sad(ness|est|er)?)\\b',\\\n",
    "                              '_dissapointing_',regex=True, case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         buy ! break fast spun 15 minutes end flew n't ...\n",
       "1            showed 's shown . someone 's old toy . paint .\n",
       "2         need expansion packs 3-5 want access player ai...\n",
       "3         `` gift husband new pool . receive color _boug...\n",
       "4               received pineapple rather advertised s'more\n",
       "                                ...                        \n",
       "114912                                             fun game\n",
       "114913                      `` _great_ kit , well priced ''\n",
       "114914                                           supposed .\n",
       "114915          grandson loves playing police figurines…… .\n",
       "114916                          grandson loves littlebits !\n",
       "Length: 114917, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_reviews_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n",
    "\n",
    "### iii).\n",
    "\n",
    "#### I have stemmed the reviews here since I'll want to maximize reach in this case by virtue of increasing \n",
    "#### the recall at the expense of precision. Also stemming si faster, so since we had a larger dataset I preferred it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"buy ! break fast spun 15 minutes end flew n't _dissapointing_ money . made cheap plastic cracks . buy poi balls work lot better limited funds .\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_reviews_s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_reviews=[]\n",
    "for review in cleaned_reviews_s:\n",
    "    words = nltk.word_tokenize(review)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(stemmer.stem(word))\n",
    "    stemmed_review = \" \".join(new_words)\n",
    "    stemmed_reviews.append(stemmed_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_reviews_s=pd.Series(stemmed_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"buy ! break fast spun 15 minut end flew n't _dissapointing_ money . made cheap plastic crack . buy poi ball work lot better limit fund .\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_reviews_s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\",token_pattern=r'\\b[A-za-z]+\\b',min_df=0.001) \n",
    "X = vectorizer.fit_transform(stemmed_reviews_s)\n",
    "vectorizer.fit(stemmed_reviews)\n",
    "vectorized_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_bad_</th>\n",
       "      <th>_bought_</th>\n",
       "      <th>_dissapointing_</th>\n",
       "      <th>_great_</th>\n",
       "      <th>_perfect_</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>absolut</th>\n",
       "      <th>...</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yo</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1382 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _bad_  _bought_  _dissapointing_  _great_  _perfect_  aa  aaa  abil  abl  \\\n",
       "0      0         0                1        0          0   0    0     0    0   \n",
       "1      0         0                0        0          0   0    0     0    0   \n",
       "2      0         0                0        0          0   0    0     0    0   \n",
       "3      1         1                0        0          0   0    0     0    0   \n",
       "4      0         0                0        0          0   0    0     0    0   \n",
       "\n",
       "   absolut  ...  yesterday  yo  young  younger  youngest  youtub  yr  zero  \\\n",
       "0        0  ...          0   0      0        0         0       0   0     0   \n",
       "1        0  ...          0   0      0        0         0       0   0     0   \n",
       "2        0  ...          0   0      0        0         0       0   0     0   \n",
       "3        0  ...          0   0      0        0         0       0   0     0   \n",
       "4        0  ...          0   0      0        0         0       0   0     0   \n",
       "\n",
       "   zip  zipper  \n",
       "0    0       0  \n",
       "1    0       0  \n",
       "2    0       0  \n",
       "3    0       0  \n",
       "4    0       0  \n",
       "\n",
       "[5 rows x 1382 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114917 entries, 0 to 114916\n",
      "Columns: 1382 entries, _bad_ to zipper\n",
      "dtypes: int64(1382)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "vectorized_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.\n",
    "\n",
    "## MCDONALDS\n",
    "\n",
    "(treated each review as document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>city</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>679455653</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>I'm not a huge mcds lover, but I've been to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>679455654</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Terrible customer service. I came in at 9:30pm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>679455655</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>First they \"lost\" my order, actually they gave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>679455656</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>I see I'm not the only one giving 1 star. Only...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>679455657</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Well, it's McDonald's, so you know what the fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id     city                                             review\n",
       "0  679455653  Atlanta  I'm not a huge mcds lover, but I've been to be...\n",
       "1  679455654  Atlanta  Terrible customer service. I came in at 9:30pm...\n",
       "2  679455655  Atlanta  First they \"lost\" my order, actually they gave...\n",
       "3  679455656  Atlanta  I see I'm not the only one giving 1 star. Only...\n",
       "4  679455657  Atlanta  Well, it's McDonald's, so you know what the fo..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "data=pd.read_csv(\"../datasets/mcdonalds-yelp-negative-reviews.csv\", encoding=\"latin1\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SOME BASC REGEX CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#REGEX1\n",
    "data[\"review\"]=data[\"review\"].str.replace(r'\\b(mcd(onald(s)?|s)?)\\b','_McD_',regex=True, case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGEX2\n",
    "data[\"review\"]=data['review'].str.replace(r'\\b(unfriendly)\\b|\\b(rude(ly|ness)?)\\b|\\b(unkind(ness)?)\\b',\\\n",
    "                                             '_rude_',regex=True, case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#REGEX3\n",
    "data[\"review\"]=data['review'].str.replace(r'\\b(filthy)\\b|\\b(unclean)\\b|\\b(dirty)\\b',\\\n",
    "                                             '_unclean_',regex=True, case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. STEMMING AND and COUNT VECTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_reviews_mcd=[]\n",
    "for review in data[\"review\"]:\n",
    "    words = nltk.word_tokenize(review)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(stemmer.stem(word.lower()))         #appending lowercased tokens\n",
    "    stemmed_review = \" \".join(new_words)\n",
    "    stemmed_reviews_mcd.append(stemmed_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_reviews_mcd_s=pd.Series(stemmed_reviews_mcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       i 'm not a huge _mcd_ lover , but i 've been t...\n",
       "1       terribl custom servic . i came in at 9:30pm an...\n",
       "2       first they `` lost '' my order , actual they g...\n",
       "3       i see i 'm not the onli one give 1 star . onli...\n",
       "4       well , it 's mcdonald 's , so you know what th...\n",
       "                              ...                        \n",
       "1520    i enjoy the part where i repeatedli ask if i h...\n",
       "1521    worst mcdonald i 've been in in a long time ! ...\n",
       "1522    when i am realli crave for mcdonald 's , thi s...\n",
       "1523    two point right out of the gate : 1 . thuggeri...\n",
       "1524    i want to grab breakfast one morn befor work s...\n",
       "Length: 1525, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_reviews_mcd_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\",token_pattern=r'\\b[A-za-z]{3,}\\b') \n",
    "X = vectorizer.fit_transform(stemmed_reviews_mcd_s)\n",
    "vectorizer.fit(stemmed_reviews_mcd_s)\n",
    "vectorized_df1 = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_and</th>\n",
       "      <th>_mcd_</th>\n",
       "      <th>_rude_</th>\n",
       "      <th>_unclean_</th>\n",
       "      <th>aaaaaaaahhhhhhhhhhh</th>\n",
       "      <th>abbrevi</th>\n",
       "      <th>abc</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abod</th>\n",
       "      <th>...</th>\n",
       "      <th>zak</th>\n",
       "      <th>zax</th>\n",
       "      <th>zee</th>\n",
       "      <th>zeke</th>\n",
       "      <th>zero</th>\n",
       "      <th>zesti</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5863 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _and  _mcd_  _rude_  _unclean_  aaaaaaaahhhhhhhhhhh  abbrevi  abc  abil  \\\n",
       "0     0      1       1          1                    0        0    0     0   \n",
       "1     0      0       0          1                    0        0    0     0   \n",
       "2     0      0       0          0                    0        0    0     0   \n",
       "3     0      0       0          0                    0        0    0     0   \n",
       "4     0      0       1          0                    0        0    0     0   \n",
       "\n",
       "   abl  abod  ...  zak  zax  zee  zeke  zero  zesti  zip  zombi  zombie  zoom  \n",
       "0    0     0  ...    0    0    0     0     0      0    0      0       0     0  \n",
       "1    0     0  ...    0    0    0     0     0      0    0      0       0     0  \n",
       "2    0     0  ...    0    0    0     0     0      0    0      0       0     0  \n",
       "3    0     0  ...    0    0    0     0     0      0    0      0       0     0  \n",
       "4    0     0  ...    0    0    0     0     0      0    0      0       0     0  \n",
       "\n",
       "[5 rows x 5863 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5863 features in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LEMMATIZATION AND VECTORIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercased__reviews=[]         #LOWERCASING ALL TOKENS\n",
    "for review in data[\"review\"]:\n",
    "    words = nltk.word_tokenize(review)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(word.lower())\n",
    "    lowercased_review = \" \".join(new_words)\n",
    "    lowercased__reviews.append(lowercased_review)\n",
    "lowercased__reviews_s=pd.Series(lowercased__reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lemmatization\n",
    "## https://gist.github.com/gaurav5430/9fce93759eb2f6b1697883c3782f30de#file-nltk-lemmatize-sentences-py\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_reviews_mcd=[]\n",
    "for review in pd.Series(lowercased__reviews_s):\n",
    "    lemm_review=lemmatize_sentence(review)\n",
    "    lemm_reviews_mcd.append(lemm_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_reviews_mcd_s=pd.Series(lemm_reviews_mcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i 'm not a huge _mcd_ lover , but i 've be to good one . this be by far the bad one i 've ever be too ! it 's _unclean_ inside and if you get drive through they completely screw up your order every time ! the staff be terribly _rude_ and nobody seem to care .\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm_reviews_mcd_s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i 'm not a huge _mcd_ lover , but i 've been to better ones . this is by far the worst one i 've ever been too ! it 's _unclean_ inside and if you get drive through they completely screw up your order every time ! the staff is terribly _rude_ and nobody seems to care .\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowercased__reviews_s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\",token_pattern=r'\\b[A-za-z]{3,}\\b') \n",
    "X = vectorizer.fit_transform(lemm_reviews_mcd_s)\n",
    "vectorizer.fit(lemm_reviews_mcd_s)\n",
    "vectorized_df2 = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_and</th>\n",
       "      <th>_mcd_</th>\n",
       "      <th>_rude_</th>\n",
       "      <th>_unclean_</th>\n",
       "      <th>aaaaaaaahhhhhhhhhhh</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abode</th>\n",
       "      <th>...</th>\n",
       "      <th>yuppie</th>\n",
       "      <th>zak</th>\n",
       "      <th>zax</th>\n",
       "      <th>zee</th>\n",
       "      <th>zeke</th>\n",
       "      <th>zero</th>\n",
       "      <th>zesty</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1525 rows × 6380 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _and  _mcd_  _rude_  _unclean_  aaaaaaaahhhhhhhhhhh  abbreviate  abc  \\\n",
       "0        0      1       1          1                    0           0    0   \n",
       "1        0      0       0          1                    0           0    0   \n",
       "2        0      0       0          0                    0           0    0   \n",
       "3        0      0       0          0                    0           0    0   \n",
       "4        0      0       1          0                    0           0    0   \n",
       "...    ...    ...     ...        ...                  ...         ...  ...   \n",
       "1520     0      0       0          0                    0           0    0   \n",
       "1521     0      0       0          0                    0           0    0   \n",
       "1522     0      0       0          0                    0           0    0   \n",
       "1523     0      0       0          0                    0           0    0   \n",
       "1524     0      0       0          0                    0           0    0   \n",
       "\n",
       "      ability  able  abode  ...  yuppie  zak  zax  zee  zeke  zero  zesty  \\\n",
       "0           0     0      0  ...       0    0    0    0     0     0      0   \n",
       "1           0     0      0  ...       0    0    0    0     0     0      0   \n",
       "2           0     0      0  ...       0    0    0    0     0     0      0   \n",
       "3           0     0      0  ...       0    0    0    0     0     0      0   \n",
       "4           0     0      0  ...       0    0    0    0     0     0      0   \n",
       "...       ...   ...    ...  ...     ...  ...  ...  ...   ...   ...    ...   \n",
       "1520        0     0      0  ...       0    0    0    0     0     0      0   \n",
       "1521        0     0      0  ...       0    0    0    0     0     0      0   \n",
       "1522        0     0      0  ...       0    0    0    0     0     0      0   \n",
       "1523        0     0      0  ...       0    0    0    0     0     1      0   \n",
       "1524        0     0      0  ...       0    0    0    0     0     0      0   \n",
       "\n",
       "      zip  zombie  zoom  \n",
       "0       0       0     0  \n",
       "1       0       0     0  \n",
       "2       0       0     0  \n",
       "3       0       0     0  \n",
       "4       0       0     0  \n",
       "...   ...     ...   ...  \n",
       "1520    0       0     0  \n",
       "1521    0       0     0  \n",
       "1522    0       0     0  \n",
       "1523    0       0     0  \n",
       "1524    0       0     0  \n",
       "\n",
       "[1525 rows x 6380 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6380 features in total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. STOPWORDS REMOVAL AND VECTORIZATION (ON LEMMATIZED DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_stopwords=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews_mcd=[]\n",
    "\n",
    "for review in lemm_reviews_mcd_s:\n",
    "    words = nltk.word_tokenize(review)\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.lower() in nltk_stopwords:\n",
    "            continue\n",
    "        new_words.append(word.lower())\n",
    "    cleaned_review = \" \".join(new_words)\n",
    "    cleaned_reviews_mcd.append(cleaned_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews_mcd_s=pd.Series(cleaned_reviews_mcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    'm huge _mcd_ lover , 've good one . far bad o...\n",
       "1    terrible customer service . come 9:30pm stand ...\n",
       "2    first `` lose `` order , actually give someone...\n",
       "3    see 'm one give 1 star . -25 star ! ! ! 's nee...\n",
       "4    well , 's mcdonald 's , know food . review ref...\n",
       "dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_reviews_mcd_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"first they `` lose `` my order , actually they give it to someone one else than take 20 minute to figure out why i be still wait for my order.they after i be ask what i need i reply , `` my order `` .they ask for my ticket and the asst mgr look at the ticket then incompletely fill it.i have to ask her to check to see if she fill it correctly.she act as if she could n't be bother with that so i ask her again.she begrudgingly check to she do in fact miss something on the ticket.so after 22 minute i finally have my breakfast biscuit platter.as i leave an woman approach and identify herself as the manager , she be dress as if she have just awake in an old t-shirt and sweat pants.she say she have hear what happen and say she 'd take care of it.well why do n't she intervene when she saw i be grow annoy with the incompetence ?\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemm_reviews_mcd_s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"first `` lose `` order , actually give someone one else take 20 minute figure still wait order.they ask need reply , `` order `` .they ask ticket asst mgr look ticket incompletely fill it.i ask check see fill correctly.she act could n't bother ask again.she begrudgingly check fact miss something ticket.so 22 minute finally breakfast biscuit platter.as leave woman approach identify manager , dress awake old t-shirt sweat pants.she say hear happen say 'd take care it.well n't intervene saw grow annoy incompetence ?\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_reviews_mcd_s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\",token_pattern=r'\\b[A-za-z]{3,}\\b') \n",
    "X = vectorizer.fit_transform(cleaned_reviews_mcd_s)\n",
    "vectorized_df3 = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_and</th>\n",
       "      <th>_mcd_</th>\n",
       "      <th>_rude_</th>\n",
       "      <th>_unclean_</th>\n",
       "      <th>aaaaaaaahhhhhhhhhhh</th>\n",
       "      <th>abbreviate</th>\n",
       "      <th>abc</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abode</th>\n",
       "      <th>...</th>\n",
       "      <th>yuppie</th>\n",
       "      <th>zak</th>\n",
       "      <th>zax</th>\n",
       "      <th>zee</th>\n",
       "      <th>zeke</th>\n",
       "      <th>zero</th>\n",
       "      <th>zesty</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1525 rows × 6378 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      _and  _mcd_  _rude_  _unclean_  aaaaaaaahhhhhhhhhhh  abbreviate  abc  \\\n",
       "0        0      1       1          1                    0           0    0   \n",
       "1        0      0       0          1                    0           0    0   \n",
       "2        0      0       0          0                    0           0    0   \n",
       "3        0      0       0          0                    0           0    0   \n",
       "4        0      0       1          0                    0           0    0   \n",
       "...    ...    ...     ...        ...                  ...         ...  ...   \n",
       "1520     0      0       0          0                    0           0    0   \n",
       "1521     0      0       0          0                    0           0    0   \n",
       "1522     0      0       0          0                    0           0    0   \n",
       "1523     0      0       0          0                    0           0    0   \n",
       "1524     0      0       0          0                    0           0    0   \n",
       "\n",
       "      ability  able  abode  ...  yuppie  zak  zax  zee  zeke  zero  zesty  \\\n",
       "0           0     0      0  ...       0    0    0    0     0     0      0   \n",
       "1           0     0      0  ...       0    0    0    0     0     0      0   \n",
       "2           0     0      0  ...       0    0    0    0     0     0      0   \n",
       "3           0     0      0  ...       0    0    0    0     0     0      0   \n",
       "4           0     0      0  ...       0    0    0    0     0     0      0   \n",
       "...       ...   ...    ...  ...     ...  ...  ...  ...   ...   ...    ...   \n",
       "1520        0     0      0  ...       0    0    0    0     0     0      0   \n",
       "1521        0     0      0  ...       0    0    0    0     0     0      0   \n",
       "1522        0     0      0  ...       0    0    0    0     0     0      0   \n",
       "1523        0     0      0  ...       0    0    0    0     0     1      0   \n",
       "1524        0     0      0  ...       0    0    0    0     0     0      0   \n",
       "\n",
       "      zip  zombie  zoom  \n",
       "0       0       0     0  \n",
       "1       0       0     0  \n",
       "2       0       0     0  \n",
       "3       0       0     0  \n",
       "4       0       0     0  \n",
       "...   ...     ...   ...  \n",
       "1520    0       0     0  \n",
       "1521    0       0     0  \n",
       "1522    0       0     0  \n",
       "1523    0       0     0  \n",
       "1524    0       0     0  \n",
       "\n",
       "[1525 rows x 6378 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6378 features in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
